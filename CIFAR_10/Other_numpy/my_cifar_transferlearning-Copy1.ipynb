{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:10.347850Z",
     "start_time": "2017-09-09T01:20:10.339850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meu nome é: Gabriel Moraes Barros \n",
      "Meu RA é: 192801\n"
     ]
    }
   ],
   "source": [
    "print('Meu nome é: Gabriel Moraes Barros ')\n",
    "print('Meu RA é: 192801')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras  2.0.5\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import (SGD, \n",
    "                              RMSprop, \n",
    "                              Adam, \n",
    "                              Adadelta, \n",
    "                              Adagrad)\n",
    "\n",
    "print('Keras ', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "nr.seed(20170603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_keras_utilities.py  __pycache__\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../utils')\n",
    "from my_keras_utilities import (get_available_gpus, \n",
    "                                load_model_and_history, \n",
    "                                save_model_and_history, \n",
    "                                TrainingPlotter, train_network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testa se um modulo foi importado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'my_keras_utilities' in sys.modules\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try:\n",
    "    train_network(model_week05, model_name, train_generator, validation_generator, **fit_params);\n",
    "except AttributeError:\n",
    "      print('nope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:10.882645Z",
     "start_time": "2017-09-09T01:20:10.751750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend:        tensorflow\n",
      "Data format:    channels_first\n",
      "/bin/sh: 1: nvidia-smib: not found\r\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "K.set_floatx('float32')\n",
    "print('Backend:        {}'.format(K.backend()))\n",
    "print('Data format:    {}'.format(K.image_data_format()))\n",
    "!nvidia-smib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:11.258830Z",
     "start_time": "2017-09-09T01:20:11.118586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../Task 5': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../Task\\ 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCb(TrainingPlotter):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "\n",
    "\n",
    "def train_network(model, model_name, train_generator, validation_generator, \n",
    "                  train_steps=10, valid_steps=10, opt='rmsprop', nepochs=50, \n",
    "                  patience=50, reset=False, ploss=1.0):\n",
    "\n",
    "    do_plot = (ploss > 0.0)\n",
    "    \n",
    "    model_fn = model_name + '.model'\n",
    "    if reset and os.path.isfile(model_fn):\n",
    "        os.unlink(model_name + '.model')\n",
    "        \n",
    "    if not os.path.isfile(model_fn):\n",
    "        # initialize the optimizer and model\n",
    "        print(\"[INFO] compiling model...\")\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])    \n",
    "\n",
    "        # History, checkpoint, earlystop, plot losses:\n",
    "        cb = [ModelCheckpoint(model_file, monitor='val_acc', verbose=0, save_best_only=True, mode='auto', period=1),\n",
    "        MyCb(n=1, filepath=model_name, patience=patience, plot_losses=do_plot), \n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=7, verbose=0, mode='auto', epsilon=0.00001, cooldown=0, min_lr=0)\n",
    "     ]\n",
    "        \n",
    "    else:\n",
    "        print(\"[INFO] loading model...\")\n",
    "        model, cb = load_model_and_history(model_name)\n",
    "        cb.patience = patience\n",
    "\n",
    "    past_epochs = cb[1].get_nepochs()\n",
    "    tr_epochs = nepochs - past_epochs\n",
    "    \n",
    "    if do_plot:\n",
    "        vv = 0\n",
    "        fig = plot.figure(figsize=(15,6))\n",
    "        plot.ylim(0.0, ploss)\n",
    "        plot.xlim(0, nepochs)\n",
    "        plot.grid(True)\n",
    "    else:\n",
    "        vv = 2\n",
    "\n",
    "    print(\"[INFO] training for {} epochs ...\".format(tr_epochs))\n",
    "    try:\n",
    "        model.fit_generator(train_generator, steps_per_epoch=train_steps,\n",
    "                            validation_data=validation_generator, validation_steps=valid_steps,\n",
    "                            epochs=nepochs, verbose=vv, callbacks=[cb[1]])\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    model, histo = load_model_and_history(model_name)\n",
    "    return model, cb\n",
    "\n",
    "\n",
    "def test_network(model_name, validation_generator, nb_validation_samples):\n",
    "    model, histo = load_model_and_history(model_name)\n",
    "    print('Model from epoch {}'.format(histo.best_epoch))\n",
    "    print(\"[INFO] evaluating in the test data set ...\")\n",
    "    loss, accuracy = model.evaluate_generator(validation_generator, nb_validation_samples)\n",
    "    print(\"\\n[INFO] accuracy on the test data set: {:.2f}% [{:.5f}]\".format(accuracy * 100, loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subindo o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:12.005955Z",
     "start_time": "2017-09-09T01:20:12.000245Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#auternar o comentário, se estiver no client ou no remote\n",
    "data = np.load('/etc/jupyterhub/ia368z_2s2017/datasets/cifar10-redux.npz')\n",
    "#data = np.load('../Task 5/cifar10-redux.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:12.265870Z",
     "start_time": "2017-09-09T01:20:12.244731Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:12.504461Z",
     "start_time": "2017-09-09T01:20:12.496212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), dtype('uint8'), dtype('uint8'), dtype('int64'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype, y_train.dtype, X_test.dtype, y_test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando o conjunto de treinamento em validação e treinamento, numa proporção 80/20 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adessowiki/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/adessowiki/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/adessowiki/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/adessowiki/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:10: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "p=np.random.permutation(len(X_train))\n",
    "percent_factor=0.85\n",
    "new_train_x = X_train[p]\n",
    "new_train_y = y_train[p]\n",
    "\n",
    "\n",
    "new_X_train = new_train_x[0:(np.floor(len(new_train_x)*percent_factor))]\n",
    "new_y_train = new_train_y[0:(np.floor(len(new_train_y)*percent_factor))]\n",
    "new_X_val = new_train_x[(np.ceil(len(new_train_x)*percent_factor)):]\n",
    "new_y_val = new_train_y[(np.ceil(len(new_train_y)*percent_factor)):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:12.773731Z",
     "start_time": "2017-09-09T01:20:12.765869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (1700, 3, 32, 32)\n",
      "y_train.shape (1700,)\n",
      "X_val.shape (300, 3, 32, 32)\n",
      "y_val.shape (300,)\n",
      "y_test shape  (500,)\n",
      "X_test.shape: (500, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape',new_X_train.shape)\n",
    "print('y_train.shape',new_y_train.shape)\n",
    "print('X_val.shape',new_X_val.shape)\n",
    "print('y_val.shape',new_y_val.shape)\n",
    "print('y_test shape ',y_test.shape)\n",
    "print('X_test.shape:',X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:13.107292Z",
     "start_time": "2017-09-09T01:20:13.102728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de diferentes classes 3\n"
     ]
    }
   ],
   "source": [
    "print('Número de diferentes classes',len(np.unique(y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:13.816180Z",
     "start_time": "2017-09-09T01:20:13.799877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.781868652\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "print(np.mean(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:14.172398Z",
     "start_time": "2017-09-09T01:20:14.135961Z"
    }
   },
   "source": [
    "#Guaranteeing that it only runs once\n",
    "if (a==0):\n",
    "    X_test = X_test.astype('float32')\n",
    "    new_X_train = new_X_train.astype('float32')\n",
    "    new_X_val = new_X_val.astype('float32')\n",
    "    \n",
    "    new_X_val /= 255.\n",
    "    new_X_train /= 255.\n",
    "    X_test /= 255.\n",
    "    \n",
    "    a=1\n",
    "print(np.mean(new_X_train))\n",
    "print(np.mean(new_X_val))\n",
    "print(np.mean(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "## Transforma o vetor de labels para o formato de one-hot encoding.\n",
    "n_classes = 3\n",
    "y_train_oh = np_utils.to_categorical(new_y_train-3, n_classes)\n",
    "y_val_oh = np_utils.to_categorical(new_y_val-3, n_classes)\n",
    "y_test_oh = np_utils.to_categorical(y_test-3, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:14.948527Z",
     "start_time": "2017-09-09T01:20:14.942812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 3)\n",
      "(300, 3)\n",
      "(500, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_oh.shape)\n",
    "print(y_val_oh.shape)\n",
    "print(y_test_oh.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo o data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:20:15.670473Z",
     "start_time": "2017-09-09T01:20:15.664241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3, 32, 32)\n",
      "(500, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new x train shape (1700, 3, 32, 32)\n",
      "y train oh shape (1700, 3)\n",
      "new x val shape (300, 3, 32, 32)\n",
      "y val oh shape (300, 3)\n"
     ]
    }
   ],
   "source": [
    "print('new x train shape', new_X_train.shape)\n",
    "print('y train oh shape', y_train_oh.shape)\n",
    "\n",
    "print('new x val shape', new_X_val.shape)\n",
    "print('y val oh shape', y_val_oh.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb val samples 300\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "nb_train_samples = new_train_x.shape[0]\n",
    "nb_val_samples = new_X_val.shape[0]\n",
    "print('nb val samples',nb_val_samples)\n",
    "nb_test_samples = X_test.shape[0]\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 32, 32\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "aug_datagen = ImageDataGenerator(\n",
    "       rescale=1./255,         # sempre faz o rescale\n",
    "       shear_range=0.2,        # sorteio entre 0 e 0.2 distribuição uniforme\n",
    "       zoom_range=0.2,         # sorteio entre 0 e 0.2\n",
    "       horizontal_flip=True)   # sorteio 50%\n",
    "\n",
    "non_aug_datagen = ImageDataGenerator( rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = aug_datagen.flow(\n",
    "        x = new_X_train, y = y_train_oh,                       # as amostras de treinamento\n",
    "        batch_size=batch_size,shuffle=False                # batch size do SGD\n",
    "        )\n",
    "\n",
    "validation_generator = non_aug_datagen.flow(\n",
    "        x = new_X_val, y = y_val_oh,                  # as amostras de validação\n",
    "        batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_generator = non_aug_datagen.flow(\n",
    "        x = X_test, y = y_test_oh,                  # as amostras de validação\n",
    "        batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:21:21.747496Z",
     "start_time": "2017-09-09T01:21:21.729673Z"
    },
    "collapsed": true
   },
   "source": [
    "#Conjunto de treinaemnto\n",
    "samples_train = train_datagen.flow(new_X_train)\n",
    "n_samples_train = nb_train_samples/batch_size\n",
    "\n",
    "#Conjunto de teste\n",
    "samples_test = train_datagen.flow(X_test)\n",
    "n_samples_test = nb_test_samples/batch_size\n",
    "#Conjunto de validacao\n",
    "\n",
    "samples_val = train_datagen.flow(new_X_val)\n",
    "n_samples_val = nb_val_samples/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T01:21:25.667573Z",
     "start_time": "2017-09-09T01:21:25.660405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(np.unique(y_test))\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer_Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subindo a VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T00:58:01.450645Z",
     "start_time": "2017-09-09T00:57:23.054835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/applications/vgg16.py:181: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "modelvgg = VGG16(include_top=False, weights='imagenet',classes=y_train_oh.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 512, 1, 1) float32\n",
      "(300, 512, 1, 1) float32\n"
     ]
    }
   ],
   "source": [
    "train_feature = modelvgg.predict_generator(generator=train_generator, steps=int(np.round(train_generator.n / batch_size)))\n",
    "print(train_feature.shape, train_feature.dtype)\n",
    "validation_features = modelvgg.predict_generator(generator = validation_generator, steps=int(np.round(validation_generator.n / batch_size)))\n",
    "print(validation_features.shape, validation_features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelvgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 512)\n"
     ]
    }
   ],
   "source": [
    "train_feature.shape[1:]\n",
    "train_feat = train_feature.reshape(1700,512)\n",
    "print(train_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelvgg.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_build():\n",
    "    img_rows, img_cols = 32, 32 # Dimensões das imagens\n",
    "    #imagens com 3 canais e 32x32\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "\n",
    "    # Definindo a rede\n",
    "    model = Sequential()\n",
    "    #primeira conv\n",
    "    model.add(Conv2D(32, (3, 3),\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #segunda conv\n",
    "    model.add(Conv2D(32,(3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Aqui os features deixam de ser imagens\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "model_week05 = model_build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "model_week05.load_weights('../my_cifar_dataplus_model_weights.h5')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 30, 30)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 30, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 28, 28)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 28, 28)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 813,475\n",
      "Trainable params: 813,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_week05.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.layers.convolutional.Conv2D object at 0x7f2475f62048>, <keras.layers.core.Activation object at 0x7f246f82e390>, <keras.layers.convolutional.Conv2D object at 0x7f246f82e7f0>, <keras.layers.core.Activation object at 0x7f246c636fd0>, <keras.layers.pooling.MaxPooling2D object at 0x7f2475f61fd0>, <keras.layers.core.Dropout object at 0x7f246c5f5e80>, <keras.layers.core.Flatten object at 0x7f2475f62b70>, <keras.layers.core.Dense object at 0x7f24b0f24a20>, <keras.layers.core.Activation object at 0x7f246c696630>, <keras.layers.core.Dropout object at 0x7f246c696cc0>, <keras.layers.core.Dense object at 0x7f246c696b00>, <keras.layers.core.Activation object at 0x7f24702d7cc0>]\n",
      "12\n",
      "(128, 3) (3,)\n",
      "(6272, 128) (128,)\n"
     ]
    }
   ],
   "source": [
    "print(model_week05.layers)\n",
    "print(len(model_week05.layers))\n",
    "weights10 = model_week05.layers[10].get_weights()\n",
    "print(weights10[0].shape,weights10[1].shape)\n",
    "weights7 = model_week05.layers[7].get_weights()\n",
    "print(weights7[0].shape,weights7[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2, b2 = weights10\n",
    "w1, b1 = weights7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topmodel = Sequential()\n",
    "topmodel.add(layer=keras.layers.Flatten(input_shape=(1,1,512)))\n",
    "# topmodel.add(layer=keras.layers.Dense(units=256, activation='relu', name='d256'))\n",
    "\n",
    "topmodel.add(layer=keras.layers.Dense(units=128, name='d256',))\n",
    "topmodel.add(Activation('relu'))\n",
    "topmodel.add(layer=keras.layers.Dropout(rate=.5))\n",
    "topmodel.add(layer=keras.layers.Dense(units=3, name='d3'))\n",
    "topmodel.add(Activation('softmax'))\n",
    "# topmodel.compile(optimizer=keras.optimizers.SGD(lr=.05, momentum=.9, nesterov=True),\n",
    "topmodel.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "d256 (Dense)                 (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "d3 (Dense)                   (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 66,051\n",
      "Trainable params: 66,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "topmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.layers.core.Flatten object at 0x7f2470139198>, <keras.layers.core.Dense object at 0x7f2470139208>, <keras.layers.core.Activation object at 0x7f247021f828>, <keras.layers.core.Dropout object at 0x7f2470139ba8>, <keras.layers.core.Dense object at 0x7f24701392e8>, <keras.layers.core.Activation object at 0x7f24701396a0>]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(topmodel.layers)\n",
    "print(len(topmodel.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer \"activation_5\" with a  weight list of length 2, but the layer was expecting 0 weights. Provided weights: [array([[ 0.02028346,  0.01141502, -0.00417125, .....",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-02617b8b6a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtopmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1178\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m                              \u001b[0;34m' weights. Provided weights: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m                              str(weights)[:50] + '...')\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"activation_5\" with a  weight list of length 2, but the layer was expecting 0 weights. Provided weights: [array([[ 0.02028346,  0.01141502, -0.00417125, ....."
     ]
    }
   ],
   "source": [
    "topmodel.layers[20].set_weights([w1, b1])\n",
    "topmodel.layers[5].set_weights([wei])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar_redux_augmented_vgg.history   utils   week05\r\n",
      "cifar_redux_augmented_vgg.model     week02  week06\r\n",
      "models\t\t\t\t    week03\r\n",
      "my_cifar_dataplus_model_weights.h5  week04\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w1, b1, w2, b2 = load_model('../my_cifar_dataplus_model_weights.h5').get_weights()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w1, b1, w2, b2 = load_model('../my_cifar_dataplus_model_weights').get_weights()m m  mmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 4 layers into a model with 2 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-c7cff887f8b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../my_cifar_dataplus_model_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2979\u001b[0m                          \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m                          \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2981\u001b[0;31m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[1;32m   2982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m     \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 4 layers into a model with 2 layers."
     ]
    }
   ],
   "source": [
    "model2.load_weights('../my_cifar_dataplus_model_weights.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    # Aqui os features deixam de ser imagens\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topmodel = Sequential()\n",
    "# topmodel.add(layer=keras.layers.Flatten(input_shape=feat_train.shape[1:]))\n",
    "# topmodel.add(layer=keras.layers.Dense(units=256, activation='relu', name='d256'))\n",
    "topmodel.add(layer=keras.layers.Dense(units=256, activation='relu', name='d256', input_shape=(1,1,512)))\n",
    "topmodel.add(layer=keras.layers.Dropout(rate=.5))\n",
    "topmodel.add(layer=keras.layers.Dense(units=3, activation='softmax', name='d3'))\n",
    "\n",
    "# topmodel.compile(optimizer=keras.optimizers.SGD(lr=.05, momentum=.9, nesterov=True),\n",
    "topmodel.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#train_features = modelvgg.predict(new_X_train)\n",
    "train_features = modelvgg.predict(new_X_train)\n",
    "\n",
    "print('train_features shape and type',train_features.shape,train_features.dtype)\n",
    "validation_features = modelvgg.predict(new_X_val)\n",
    "print('validation_features shape and type',validation_features.shape,train_features.dtype)\n",
    "test_features = modelvgg.predict(X_test)\n",
    "print('test_features shape and type',test_features.shape,train_features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelvgg.layers.pop(18)\n",
    "modelvgg.layers.pop(17)\n",
    "modelvgg.layers.pop(16)\n",
    "modelvgg.layers.pop(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modelvgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = modelvgg.predict(new_X_train)\n",
    "print('train_features shape and type',train_features.shape,train_features.dtype)\n",
    "validation_features = modelvgg.predict(new_X_val)\n",
    "print('validation_features shape and type',validation_features.shape,train_features.dtype)\n",
    "test_features = modelvgg.predict(X_test)\n",
    "print('test_features shape and type',test_features.shape,train_features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = '../cifar_redux_augmented_vgg'\n",
    "\n",
    "modelVGG = Sequential()\n",
    "modelVGG.add(Flatten(input_shape= train_features.shape[1:]))    \n",
    "modelVGG.add(Dense(120))\n",
    "modelVGG.add(Activation('relu'))\n",
    "modelVGG.add(Dropout(0.5))\n",
    "modelVGG.add(Dense(3))\n",
    "modelVGG.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelVGG.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando class MyCb(TrainingPlotter):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCb(TrainingPlotter):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "\n",
    "\n",
    "def train_network(model, model_name, Xtra, ytra, Xval, yval, \n",
    "                  opt='rmsprop', batch_size=100, nepochs=50, patience=50, reset=False, ploss=1.0):\n",
    "\n",
    "    do_plot = (ploss > 0.0)\n",
    "    \n",
    "    model_fn = model_name + '.model'\n",
    "    if reset and os.path.isfile(model_fn):\n",
    "        os.unlink(model_name + '.model')\n",
    "        \n",
    "    if not os.path.isfile(model_fn):\n",
    "        # initialize the optimizer and model\n",
    "        print(\"[INFO] compiling model...\")\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])    \n",
    "\n",
    "        # History, checkpoint, earlystop, plot losses:\n",
    "        cb = MyCb(n=1, filepath=model_name, patience=patience, plot_losses=do_plot)\n",
    "        \n",
    "    else:\n",
    "        print(\"[INFO] loading model...\")\n",
    "        model, cb = load_model_and_history(model_name)\n",
    "        cb.patience = patience\n",
    "\n",
    "    past_epochs = cb.get_nepochs()\n",
    "    tr_epochs = nepochs - past_epochs\n",
    "    \n",
    "    if do_plot:\n",
    "        vv = 0\n",
    "        fig = plot.figure(figsize=(15,6))\n",
    "        plot.ylim(0.0, ploss)\n",
    "        plot.xlim(0, nepochs)\n",
    "        plot.grid(True)\n",
    "    else:\n",
    "        vv = 2\n",
    "\n",
    "    print(\"[INFO] training for {} epochs ...\".format(tr_epochs))\n",
    "    try:\n",
    "         model.fit(Xtra, ytra, batch_size=batch_size, epochs=tr_epochs, verbose=vv, \n",
    "                      validation_data=(Xval,yval), callbacks=[cb])\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    model, histo = load_model_and_history(model_name)\n",
    "    return model, cb\n",
    "\n",
    "\n",
    "def test_network(model_name, Xtest, ytest, batch_size=40):\n",
    "    model, histo = load_model_and_history(model_name)\n",
    "    print('Model from epoch {}'.format(histo.best_epoch))\n",
    "    print(\"[INFO] evaluating in the test data set ...\")\n",
    "    loss, accuracy = model.evaluate(Xtest, ytest, batch_size=batch_size, verbose=1)\n",
    "    print(\"\\n[INFO] accuracy on the test data set: {:.2f}% [{:.5f}]\".format(accuracy * 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('train_features.shape',train_features.shape)\n",
    "print('validation_features.shape',validation_features.shape)\n",
    "print('test_features.shape',test_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'opt':         'adam',           # SGD(lr=0.01, momentum=0.9, nesterov=True), \n",
    "    'nepochs':         100, \n",
    "    'patience':        30,\n",
    "    'ploss':           1.5,\n",
    "    'reset':           True,\n",
    "}\n",
    "\n",
    "train_network(modelVGG, model_name, train_features, y_train_oh, validation_features, y_val_oh,  **fit_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_network(model_name, test_features,y_test_oh,X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "print(\"[INFO] creating model...\")\n",
    "#vgg = VGG16(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))\n",
    "vgg = VGG16(include_top=False, weights='imagenet')\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Construção da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "print(new_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n"
     ]
    }
   ],
   "source": [
    "img_height, img_width = new_X_train.shape[2],new_X_train.shape[3]\n",
    "print(img_height,img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar_redux_augmented_vgg.history  models  week02  week04  week06\r\n",
      "cifar_redux_augmented_vgg.model    utils   week03  week05\r\n"
     ]
    }
   ],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "model_name = '../cifar10_vgg_finetune'   # modelo da rede atual\n",
    "top_model_name = '../cifar_redux_augmented_vgg'\n",
    "nb_classes=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/applications/vgg16.py:181: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"global_max_pooling2d_20/Max:0\", shape=(?, 512), dtype=float32)\n",
      "[<keras.engine.topology.InputLayer object at 0x7f1ee4f962e8>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4f965f8>, <keras.layers.convolutional.Conv2D object at 0x7f1ee502db38>, <keras.layers.pooling.MaxPooling2D object at 0x7f1ee4f964a8>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4fe2588>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4fe24a8>, <keras.layers.pooling.MaxPooling2D object at 0x7f1ee4ff1d30>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4e6aef0>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4efb9e8>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4e78c18>, <keras.layers.pooling.MaxPooling2D object at 0x7f1ee4e037b8>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4dadc50>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4dbd7f0>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4d65ba8>, <keras.layers.pooling.MaxPooling2D object at 0x7f1ee4d735c0>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4c9bef0>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4cac780>, <keras.layers.convolutional.Conv2D object at 0x7f1ee4c02630>, <keras.layers.pooling.MaxPooling2D object at 0x7f1ee4c10e80>, <keras.layers.pooling.GlobalMaxPooling2D object at 0x7f1ee4b8ae80>, <keras.layers.core.Dense object at 0x7f1ee4bbc2e8>, <keras.layers.core.Dropout object at 0x7f1ee4bbce80>, <keras.layers.core.Dense object at 0x7f1ee4bbc550>, <keras.layers.core.Dropout object at 0x7f1ee4a81320>, <keras.layers.core.Dense object at 0x7f1ee4881400>]\n",
      "25\n",
      "(512, 120) (120,) (120, 3) (3,)\n"
     ]
    }
   ],
   "source": [
    "def build_net(top_model_name):\n",
    "    from keras.applications.vgg16 import VGG16\n",
    "    \n",
    "    print(\"[INFO] creating model...\")\n",
    "    #vgg = VGG16(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))\n",
    "    #vgg = VGG16(include_top=False, weights='imagenet', input_shape=(3,img_height, img_width))\n",
    "    vgg = VGG16(include_top=False, weights='imagenet', classes=nb_classes, pooling='max')\n",
    "    \n",
    "    print(vgg.output)\n",
    "    # build a classifier model and put on top of the convolutional model\n",
    "    #x = Flatten()(vgg.output)\n",
    "    x = Dense(120, activation='relu', name='dense1')(vgg.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(3, activation='relu', name='d1')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation='sigmoid', name='d2')(x)\n",
    "    \n",
    "    #x = Dense(40, activation='relu', name='dense1')(vgg.output)\n",
    "   # x = Dropout(0.5)(x)\n",
    "    #x = Dense(120, activation='relu', name='dense2')(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    #x = Dense(nb_classes, activation='softmax', name='dense3')(x)\n",
    "\n",
    "    #model = Model(inputs=vgg.input, outputs=x\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=vgg.input, outputs=x)\n",
    "    print(model.layers)\n",
    "    print(len(model.layers))    #     print('Model layers:')\n",
    "    #     for i, layer in enumerate(model.layers):\n",
    "    #         print('    {:2d} {:15s} {}'.format(i, layer.name, layer))\n",
    "    \n",
    "    # modelo da rede densa treinada no notebook anterior\n",
    "    top_model_name = top_model_name\n",
    "    # Carrego os pesos treinados anteriormente\n",
    "    #w1, b1, w2, b2 = load_model(top_model_name).get_weights()    \n",
    "    w1, b1, w2, b2 = modelVGG.get_weights()    \n",
    "    print(w1.shape,b1.shape,w2.shape,b2.shape)\n",
    "    # Coloco nas camadas densas finais da rede\n",
    "    model.layers[20].set_weights([w1, b1])\n",
    "    model.layers[22].set_weights([w2, b2])\n",
    "    \n",
    "    # Torno não-treináveis as primeiras 15 camadas\n",
    "    # da rede (os pesos não serão alterados)\n",
    "    for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    return model\n",
    "\n",
    "model = build_net(top_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "batch_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 3, 32, 32) (1700, 3) (300, 3, 32, 32) (300, 3)\n"
     ]
    }
   ],
   "source": [
    "print(new_X_train.shape, y_train_oh.shape,new_X_val.shape, y_val_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1600, 32, 32, 3) (1600, 3) (400, 32, 32, 3) (400, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected d2 to have shape (None, 1) but got array with shape (1700, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-6a9bcbdf3ef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_oh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m               )\n",
      "\u001b[0;32m/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1316\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1317\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected d2 to have shape (None, 1) but got array with shape (1700, 3)"
     ]
    }
   ],
   "source": [
    "h = model.fit(new_X_train.reshape(1700,3,32,32), y_train_oh,\n",
    "              validation_data=(new_X_val.reshape(300,3,32,32), y_val_oh),\n",
    "              batch_size=batch_size,\n",
    "              epochs=100,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = model.fit(X_train[train_i], y_train_oh[train_i],\n",
    "              validation_data=(X_train[val_i], y_train_oh[val_i]),\n",
    "              batch_size=batch_size,\n",
    "              epochs=400,\n",
    "              callbacks=[early_stopping, checkpointer, reduce_lr], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training for 100 epochs ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_25 to have shape (None, 3, None, None) but got array with shape (1700, 512, 1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-aa7d9713675c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_oh\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-555c020e6b4e>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(model, model_name, Xtra, ytra, Xval, yval, opt, batch_size, nepochs, patience, reset, ploss)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m          model.fit(Xtra, ytra, batch_size=batch_size, epochs=tr_epochs, verbose=vv, \n\u001b[0;32m---> 44\u001b[0;31m                       validation_data=(Xval,yval), callbacks=[cb])\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1309\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1312\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1313\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adessowiki/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_25 to have shape (None, 3, None, None) but got array with shape (1700, 512, 1, 1)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAAFpCAYAAAA2m3GuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAxJzAAAAAxJzAAAAAxJzAAAAA/r/A3klrwnwiWEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ee4f94550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_name = '../cifar10_vgg_finetune'\n",
    "fit_params = {\n",
    "    'opt':         'adam',           # SGD(lr=0.01, momentum=0.9, nesterov=True), \n",
    "    'nepochs':         100, \n",
    "    'patience':        30,\n",
    "    'ploss':           1.5,\n",
    "    'reset':           True,\n",
    "}\n",
    "\n",
    "train_network(model, model_name, train_features, y_train_oh, validation_features, y_val_oh,  **fit_params);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
